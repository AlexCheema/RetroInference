{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {letter:i for letter,i in zip(string.ascii_lowercase, range(1,27))}\n",
    "token_dict[' '] = 0\n",
    "token_dict['\\n'] = 27\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sentences, idx):\n",
    "        self.data = []\n",
    "\n",
    "        self.max_len = max([len(x) for x in sentences])\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if len(sentence) > idx:\n",
    "                x = torch.tensor([token_dict[x] for x in sentence[:idx]], dtype=torch.int64, device=device)\n",
    "                y = torch.tensor(token_dict[sentence[idx]], dtype=torch.int64, device=device)\n",
    "                self.data.append((x, y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_file = 'sentences.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = set(string.ascii_lowercase + ' \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open(sentences_file, 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "sentences = [x.replace('\\'', '') for x in sentences]\n",
    "sentences = [re.sub('\\W+', ' ', x.lower()).strip() for x in sentences]\n",
    "\n",
    "sentences = list(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(sentences):\n",
    "    # Length of alphabet used\n",
    "    print('token set length: ', len(list(set(''.join(sentences)))))\n",
    "\n",
    "    ## Number of unique words\n",
    "    print('unique words: ', len(list(' '.join(sentences).split(' '))))\n",
    "    print('word vocabulary length: ', len(list(set(' '.join(sentences).split(' ')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token set length:  34\n",
      "unique words:  111731\n",
      "word vocabulary length:  4125\n"
     ]
    }
   ],
   "source": [
    "print_info(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(list(' '.join(sentences).split(' '))).value_counts().values)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {x[0]:y for x,y in \n",
    "            pd.DataFrame(list(' '.join(sentences).split(' ')))\\\n",
    "                .value_counts().to_dict().items()}\n",
    "\n",
    "common_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    good = True\n",
    "\n",
    "    for word in sentence.split(' '):\n",
    "        if map_dict[word] < 10:\n",
    "            good = False\n",
    "            break\n",
    "\n",
    "    for char in sentence:\n",
    "        if char not in allowed_chars:\n",
    "            good = False\n",
    "            break\n",
    "    \n",
    "    if good:\n",
    "        common_sentences.append(sentence + '\\n')\n",
    "\n",
    "random.shuffle(common_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token set length:  28\n",
      "unique words:  73336\n",
      "word vocabulary length:  2001\n"
     ]
    }
   ],
   "source": [
    "print_info(common_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, dropout_prob=0.1):\n",
    "        super(GRUTextGenerator, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding_ff = nn.Linear(vocab_size, embed_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Dropout layer\n",
    "        \n",
    "        self.gru1 = nn.GRU(embed_size, hidden_size, 1, batch_first=True)\n",
    "        self.gru2 = nn.GRU(hidden_size, hidden_size, 1, batch_first=True)\n",
    "        self.gru3 = nn.GRU(hidden_size, hidden_size, 1, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = torch.nn.functional.one_hot(x, num_classes=self.vocab_size).float()\n",
    "        embedded = self.embedding_ff(x)\n",
    "        embedded = self.dropout(embedded)  # Apply dropout to the embedded input\n",
    "        \n",
    "        x, hidden1 = self.gru1(embedded, hidden)  # Optionally pass hidden state\n",
    "        x = self.dropout(x)  # Apply dropout after first GRU\n",
    "        \n",
    "        x, hidden2 = self.gru2(x, hidden1) \n",
    "        x = self.dropout(x)  # Apply dropout after second GRU\n",
    "        \n",
    "        x, hidden3 = self.gru3(x, hidden2)\n",
    "        x = self.dropout(x)  # Apply dropout after third GRU\n",
    "        \n",
    "        logits = self.fc(x)  # (batch_size, seq_length, vocab_size)\n",
    "        return logits, hidden3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example hyperparameters\n",
    "vocab_size = 28  # a-z and space, \\n chars\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "batch_size = 64\n",
    "\n",
    "# Create the model\n",
    "model = GRUTextGenerator(vocab_size, embed_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_path, device):\n",
    "    # Load the saved model state dictionary\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "# load_model(model, 'model_cache/model_epoch_41.pt', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloaders, vocab_size, device, epochs=10, startepoch=0, lr=0.0001, save_dir='model_cache'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    for epoch in range(startepoch, epochs):\n",
    "        total_loss = 0\n",
    "        for data_loader in dataloaders:\n",
    "            for _, (inputs, targets) in enumerate(data_loader, 0):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                logits, _ = model(inputs)  # (batch_size, seq_length, vocab_size)\n",
    "                logits = logits[:, -1, :]\n",
    "                logits = logits.view(-1, vocab_size)  # Reshape for loss calculation\n",
    "                targets = targets.view(-1)  # Reshape to match logits\n",
    "                \n",
    "                loss = criterion(logits, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss}\")\n",
    "\n",
    "        # Save the model after each epoch\n",
    "        model_path = os.path.join(save_dir, f'model_epoch_{epoch+1}.pt')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def log_epoch_to_csv(csv_path, epoch, train_loss, val_loss):\n",
    "    \"\"\"\n",
    "    Appends epoch number, training loss, and validation loss to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "        epoch (int): The current epoch number.\n",
    "        train_loss (float): Training loss for the epoch.\n",
    "        val_loss (float): Validation loss for the epoch.\n",
    "    \"\"\"\n",
    "    write_header = not os.path.exists(csv_path)  # Check if the file exists\n",
    "\n",
    "    with open(csv_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if write_header:\n",
    "            writer.writerow(['Epoch', 'Train Loss', 'Validation Loss'])\n",
    "        writer.writerow([epoch, train_loss, val_loss])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloaders, criterion, optimizer, vocab_size, device):\n",
    "    \"\"\"\n",
    "    Performs one epoch of training.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        dataloaders: List of training dataloaders.\n",
    "        criterion: Loss function.\n",
    "        optimizer: Optimizer for model training.\n",
    "        vocab_size: Size of the vocabulary.\n",
    "        device: Device to use for training.\n",
    "\n",
    "    Returns:\n",
    "        float: Average training loss for the epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data_loader in dataloaders:\n",
    "        for _, (inputs, targets) in enumerate(data_loader, 0):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits, _ = model(inputs)  # (batch_size, seq_length, vocab_size)\n",
    "            logits = logits[:, -1, :]\n",
    "            logits = logits.view(-1, vocab_size)  # Reshape for loss calculation\n",
    "            targets = targets.view(-1)  # Reshape to match logits\n",
    "\n",
    "            loss = criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / sum(len(dl) for dl in dataloaders)\n",
    "\n",
    "\n",
    "def val_epoch(model, dataloaders, criterion, vocab_size, device):\n",
    "    \"\"\"\n",
    "    Performs one epoch of evaluation.\n",
    "\n",
    "    Args:\n",
    "        model: The model to evaluate.\n",
    "        dataloaders: List of validation dataloaders.\n",
    "        criterion: Loss function.\n",
    "        vocab_size: Size of the vocabulary.\n",
    "        device: Device to use for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        float: Average validation loss for the epoch.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data_loader in dataloaders:\n",
    "            for _, (inputs, targets) in enumerate(data_loader, 0):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                logits, _ = model(inputs)  # (batch_size, seq_length, vocab_size)\n",
    "                logits = logits[:, -1, :]\n",
    "                logits = logits.view(-1, vocab_size)  # Reshape for loss calculation\n",
    "                targets = targets.view(-1)  # Reshape to match logits\n",
    "\n",
    "                loss = criterion(logits, targets)\n",
    "                total_loss += loss.item()\n",
    "    return total_loss / sum(len(dl) for dl in dataloaders)\n",
    "\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    train_dataloaders, \n",
    "    test_dataloaders, \n",
    "    vocab_size, \n",
    "    device, \n",
    "    epochs=10, \n",
    "    startepoch=0, \n",
    "    lr=0.0001, \n",
    "    save_dir='model_cache'\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model with a training and validation loop.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        train_dataloaders: List of training dataloaders.\n",
    "        test_dataloaders: List of validation dataloaders.\n",
    "        vocab_size: Size of the vocabulary.\n",
    "        device: Device to use for training.\n",
    "        epochs: Number of training epochs.\n",
    "        startepoch: Starting epoch number for resuming training.\n",
    "        lr: Learning rate for optimizer.\n",
    "        save_dir: Directory to save model checkpoints.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    if startepoch != 0:\n",
    "        load_model(model, f'model_cache/model_epoch_{startepoch}.pt', device)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for epoch in range(startepoch, epochs):\n",
    "        train_loss = train_epoch(\n",
    "            model, train_dataloaders, criterion, optimizer, vocab_size, device\n",
    "        )\n",
    "        val_loss = val_epoch(\n",
    "            model, test_dataloaders, criterion, vocab_size, device\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        log_epoch_to_csv('train_log.csv', epoch, train_loss, val_loss)\n",
    "\n",
    "        # Save the model after each epoch\n",
    "        model_path = os.path.join(save_dir, f'model_epoch_{epoch+1}.pt')\n",
    "        torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_sentences = common_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  Train Loss: 0.0682\n",
      "  Validation Loss: 4.1225\n",
      "Epoch 2/100\n",
      "  Train Loss: 0.0694\n",
      "  Validation Loss: 3.9473\n",
      "Epoch 3/100\n",
      "  Train Loss: 0.0694\n",
      "  Validation Loss: 4.0263\n",
      "Epoch 4/100\n",
      "  Train Loss: 0.0712\n",
      "  Validation Loss: 4.9881\n",
      "Epoch 5/100\n",
      "  Train Loss: 0.1336\n",
      "  Validation Loss: 3.7347\n",
      "Epoch 6/100\n",
      "  Train Loss: 0.1551\n",
      "  Validation Loss: 4.5749\n",
      "Epoch 7/100\n",
      "  Train Loss: 0.1492\n",
      "  Validation Loss: 3.9668\n",
      "Epoch 8/100\n",
      "  Train Loss: 0.0937\n",
      "  Validation Loss: 4.2988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     test_dataloaders\u001b[38;5;241m.\u001b[39mappend(DataLoader(test_dataset, batch_size))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# train(model, dataloaders, vocab_size, device, epochs=60, startepoch=42)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 109\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloaders, test_dataloaders, vocab_size, device, epochs, startepoch, lr, save_dir)\u001b[0m\n\u001b[1;32m    106\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(save_dir)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(startepoch, epochs):\n\u001b[0;32m--> 109\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m val_epoch(\n\u001b[1;32m    113\u001b[0m         model, test_dataloaders, criterion, vocab_size, device\n\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 28\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloaders, criterion, optimizer, vocab_size, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 28\u001b[0m logits, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, seq_length, vocab_size)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m     30\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vocab_size)  \u001b[38;5;66;03m# Reshape for loss calculation\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m, in \u001b[0;36mGRUTextGenerator.forward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     21\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ff(x)\n\u001b[1;32m     22\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embedded)  \u001b[38;5;66;03m# Apply dropout to the embedded input\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m x, hidden1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru1\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Optionally pass hidden state\u001b[39;00m\n\u001b[1;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)  \u001b[38;5;66;03m# Apply dropout after first GRU\u001b[39;00m\n\u001b[1;32m     27\u001b[0m x, hidden2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru2(x, hidden1) \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1102\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1106\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tt_split = 0.9\n",
    "split_loc = int(tt_split * len(common_sentences))\n",
    "\n",
    "train_dataloaders = []\n",
    "test_dataloaders = []\n",
    "\n",
    "for i in range(1, max([len(x) for x in common_sentences])):\n",
    "    test_dataset = TextDataset(common_sentences[split_loc:], i)\n",
    "    train_dataset = TextDataset(common_sentences[:split_loc], i)\n",
    "\n",
    "    train_dataloaders.append(DataLoader(train_dataset, batch_size))\n",
    "    test_dataloaders.append(DataLoader(test_dataset, batch_size))\n",
    "\n",
    "# train(model, dataloaders, vocab_size, device, epochs=60, startepoch=42)\n",
    "train(model, train_dataloaders, test_dataloaders, vocab_size, device, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise(sentence):\n",
    "    return torch.tensor([token_dict[x] for x in sentence], dtype=torch.int64, device=device)\n",
    "\n",
    "def softmax(logits, temperature=1.0):\n",
    "    scaled_logits = logits / temperature\n",
    "    exp_logits = np.exp(scaled_logits - np.max(scaled_logits))\n",
    "    probs = exp_logits / exp_logits.sum()\n",
    "    return probs\n",
    "\n",
    "def run_inference(model, sentence, temperature=1.0):\n",
    "    model.eval()\n",
    "\n",
    "    input = vectorise(sentence)\n",
    "\n",
    "    output = model(input)\n",
    "\n",
    "    logits = output[0][-1, :].detach().numpy()\n",
    "\n",
    "    # print(logits)\n",
    "\n",
    "    # Compute probabilities using softmax with temperature\n",
    "    probs = softmax(logits, temperature)\n",
    "\n",
    "    # Randomly sample from the probability distribution\n",
    "    sampled_idx = np.random.choice(len(probs), p=probs)\n",
    "\n",
    "    # sampled_idx = np.argmax(logits)\n",
    "    # print(sampled_idx)\n",
    "\n",
    "    # Find the corresponding token\n",
    "    for a, i in token_dict.items():\n",
    "        if sampled_idx == i:\n",
    "            sentence += a\n",
    "            return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the view from the mountain is great\n"
     ]
    }
   ],
   "source": [
    "sentence = random.sample(string.ascii_lowercase, 1)[0]\n",
    "sentence = 'the'\n",
    "print(sentence, end='')\n",
    "\n",
    "while sentence[-1] != '\\n':\n",
    "    sentence = run_inference(model, sentence, temperature=0.6)\n",
    "    print(sentence[-1], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from json import JSONEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeTensor(JSONEncoder,Dataset):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.cpu().detach().numpy().tolist()\n",
    "        return super(json.NpEncoder, self).default(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = vectorise(sentence)\n",
    "# y = model(x)[0]\n",
    "\n",
    "# np.savetxt('test_data/generative_gru_x.csv', x.detach(), delimiter=',')\n",
    "# np.savetxt('test_data/generative_gru_y.csv', y.detach(), delimiter=',')\n",
    "\n",
    "with open('models/generative_gru.json', 'w') as json_file:\n",
    "    json.dump(model.state_dict(), json_file,cls=EncodeTensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
