{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the model\n",
    "class GRUTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(GRUTextGenerator, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.embedding_ff = nn.Linear(vocab_size, embed_size, bias=False)\n",
    "        self.gru1 = nn.GRU(embed_size, hidden_size, 1, batch_first=True)\n",
    "        self.gru2 = nn.GRU(hidden_size, hidden_size, 1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = torch.nn.functional.one_hot(x, num_classes=self.vocab_size).float()\n",
    "        embedded = self.embedding_ff(x)\n",
    "        x, hidden = self.gru1(embedded, None)  # (batch_size, seq_length, hidden_size)\n",
    "        x, hidden = self.gru2(x, None)\n",
    "        logits = self.fc(x)  # (batch_size, seq_length, vocab_size)\n",
    "        return logits, hidden\n",
    "\n",
    "token_dict = {letter:i for letter,i in zip(string.ascii_lowercase, range(1,27))}\n",
    "token_dict[' '] = 0\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sentences, idx):\n",
    "        self.data = []\n",
    "\n",
    "        self.max_len = max([len(x) for x in sentences])\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if len(sentence) > idx:\n",
    "                x = torch.tensor([token_dict[x] for x in sentence[:idx]], dtype=torch.int64, device=device)\n",
    "                y = torch.tensor(token_dict[sentence[idx]], dtype=torch.int64, device=device)\n",
    "                self.data.append((x, y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "# Training loop\n",
    "def train(model, dataloaders, vocab_size, device, epochs=10, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for data_loader in dataloaders:\n",
    "            total_loss = 0\n",
    "            for _, (inputs, targets) in enumerate(data_loader, 0):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                logits, _ = model(inputs)  # (batch_size, seq_length, vocab_size)\n",
    "                logits = logits[:, -1, :]\n",
    "                logits = logits.view(-1, vocab_size)  # Reshape for loss calculation\n",
    "                targets = targets.view(-1)  # Reshape to match logits\n",
    "                \n",
    "                loss = criterion(logits, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(data_loader)}\")\n",
    "\n",
    "        break\n",
    "\n",
    "# Example hyperparameters\n",
    "vocab_size = 27  # a-z and a space character\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "batch_size = 64\n",
    "seq_length = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create the model\n",
    "model = GRUTextGenerator(vocab_size, embed_size, hidden_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.7557e-01,  6.7922e-02,  9.8388e-02, -1.2501e-01, -6.0013e-02,\n",
      "        -1.6312e-01, -6.9352e-02,  1.0065e-01, -3.9197e-02,  3.2594e-02,\n",
      "        -1.5702e-01,  6.6227e-02,  1.4566e-01, -1.1029e-01,  5.9280e-03,\n",
      "         6.4825e-02, -1.6047e-01, -1.6856e-01, -4.2442e-02, -7.7414e-02,\n",
      "        -3.4500e-02, -1.2600e-01, -1.1436e-01, -4.8913e-02,  5.6049e-03,\n",
      "         1.1267e-01,  8.6909e-02, -1.3511e-01, -1.4664e-01,  1.4858e-01,\n",
      "         1.5899e-01, -1.7651e-01, -1.0319e-02, -1.0715e-01, -7.3224e-02,\n",
      "        -1.5392e-01,  1.8479e-01,  7.3894e-02,  1.8040e-02,  1.4655e-01,\n",
      "         8.3047e-02,  1.7492e-01, -7.9131e-02, -1.2953e-01,  1.4146e-01,\n",
      "         1.1696e-04,  6.7882e-02,  1.7049e-01, -5.6124e-02, -4.6413e-02,\n",
      "        -1.0923e-01, -1.8666e-02,  9.0332e-02, -7.3868e-04, -3.0353e-02,\n",
      "        -3.5101e-02, -6.4153e-02, -1.4838e-02,  6.8584e-02, -6.7836e-02,\n",
      "         1.8344e-01, -1.2265e-01,  9.8370e-02, -1.5883e-01, -5.2605e-02,\n",
      "        -1.8863e-01,  1.7119e-02, -5.5684e-03, -1.7884e-01, -1.1637e-01,\n",
      "        -4.0534e-02, -1.1569e-01, -1.9157e-01,  1.1589e-01, -9.4009e-02,\n",
      "         9.6188e-02, -1.6275e-01, -1.2010e-01, -1.7175e-01,  6.3395e-02,\n",
      "         1.8262e-01, -3.6499e-02, -1.4528e-01,  1.0442e-01,  1.0181e-01,\n",
      "        -1.1007e-01,  5.6133e-02, -1.2476e-01, -1.0460e-03, -3.5255e-02,\n",
      "         5.4805e-02,  3.9849e-02,  1.2874e-02,  1.2728e-01,  1.8467e-01,\n",
      "         1.9028e-01, -1.4436e-01, -1.9137e-01, -2.3088e-02, -1.3562e-02,\n",
      "        -1.0895e-01, -8.1449e-02,  1.8650e-01, -1.6343e-01, -3.4311e-02,\n",
      "         1.3364e-01, -1.5098e-01,  6.0184e-02, -8.7503e-02, -9.4217e-02,\n",
      "         1.3966e-01, -9.6779e-02,  3.2607e-02, -1.0160e-01,  1.2486e-01,\n",
      "        -1.5860e-01, -8.2004e-02, -1.3343e-01,  8.7086e-03,  1.2060e-01,\n",
      "        -1.8388e-01, -2.6363e-02, -3.9028e-02,  1.4481e-01, -6.7897e-03,\n",
      "         1.6077e-01,  1.6747e-01, -1.8868e-01], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.embedding_ff.weight[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.000115703387564281\n"
     ]
    }
   ],
   "source": [
    "# Placeholder: Replace with your own DataLoader\n",
    "sentences = []\n",
    "with open(\"simple_sentences.txt\", 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "sentences = [x.strip() for x in sentences]\n",
    "\n",
    "dataloaders = []\n",
    "for i in range(1, max([len(x) for x in sentences])):\n",
    "    dataset = TextDataset(sentences, i)\n",
    "    dataloaders.append(DataLoader(dataset, batch_size))\n",
    "\n",
    "# Example training call\n",
    "train(model, dataloaders, vocab_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise(sentence):\n",
    "    return torch.tensor([token_dict[x] for x in sentence], dtype=torch.int64, device=device)\n",
    "\n",
    "def run_inference(model, sentence):\n",
    "    input = vectorise(sentence)\n",
    "\n",
    "    output = model(input)\n",
    "\n",
    "    logits = output[0][-1,:]\n",
    "\n",
    "    print(logits)\n",
    "\n",
    "    max_idx = logits.argmax().item()\n",
    "    for a, i in token_dict.items():\n",
    "        if max_idx == i:\n",
    "            sentence += a\n",
    "            return sentence\n",
    "    \n",
    "    print(max_idx)\n",
    "\n",
    "\n",
    "\n",
    "sentence = 'a dog run'\n",
    "# sentence = 'a'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.5538, -7.0962, -2.3684, -2.7878,  4.2614,  0.1217, -3.6715, -3.4830,\n",
      "        -2.9746, -4.4778,  1.7500, -2.6130, -4.1250, -3.8780, -5.2185, -6.5963,\n",
      "         6.9670, -3.8502,  4.0441,  6.9086, -3.4119, -7.4640, -5.0035,  1.3210,\n",
      "        -3.5759, -1.6996, -4.0673], grad_fn=<SliceBackward0>)\n",
      "a dog runp\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    sentence = run_inference(model, sentence)\n",
    "    print(sentence)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from json import JSONEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeTensor(JSONEncoder,Dataset):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.cpu().detach().numpy().tolist()\n",
    "        return super(json.NpEncoder, self).default(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorise(sentence)\n",
    "y = model(x)[0]\n",
    "\n",
    "np.savetxt('test_data/generative_gru_x.csv', x.detach(), delimiter=',')\n",
    "np.savetxt('test_data/generative_gru_y.csv', y.detach(), delimiter=',')\n",
    "\n",
    "with open('models/generative_gru.json', 'w') as json_file:\n",
    "    json.dump(model.state_dict(), json_file,cls=EncodeTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
