{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {letter:i for letter,i in zip(string.ascii_lowercase, range(1,27))}\n",
    "token_dict[' '] = 0\n",
    "token_dict['\\n'] = 27\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sentences, idx):\n",
    "        self.data = []\n",
    "\n",
    "        self.max_len = max([len(x) for x in sentences])\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if len(sentence) > idx:\n",
    "                x = torch.tensor([token_dict[x] for x in sentence[:idx]], dtype=torch.int64, device=device)\n",
    "                y = torch.tensor(token_dict[sentence[idx]], dtype=torch.int64, device=device)\n",
    "                self.data.append((x, y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_file = 'sentences.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = set(string.ascii_lowercase + ' \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open(sentences_file, 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "sentences = [x.replace('\\'', '') for x in sentences]\n",
    "sentences = [re.sub('\\W+', ' ', x.lower()).strip() for x in sentences]\n",
    "\n",
    "sentences = list(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "42222\n",
      "3352\n"
     ]
    }
   ],
   "source": [
    "## Length of alphabet used\n",
    "print(len(list(set(''.join(sentences)))))\n",
    "\n",
    "## Number of unique words\n",
    "print(len(list(' '.join(sentences).split(' '))))\n",
    "print(len(list(set(' '.join(sentences).split(' ')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(list(' '.join(sentences).split(' '))).value_counts().values)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {x[0]:y for x,y in \n",
    "            pd.DataFrame(list(' '.join(sentences).split(' ')))\\\n",
    "                .value_counts().to_dict().items()}\n",
    "\n",
    "common_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    good = True\n",
    "\n",
    "    for word in sentence.split(' '):\n",
    "        if map_dict[word] < 10:\n",
    "            good = False\n",
    "            break\n",
    "\n",
    "    for char in sentence:\n",
    "        if char not in allowed_chars:\n",
    "            good = False\n",
    "            break\n",
    "    \n",
    "    if good:\n",
    "        common_sentences.append(sentence + '\\n')\n",
    "\n",
    "random.shuffle(common_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "17294\n",
      "1021\n"
     ]
    }
   ],
   "source": [
    "## Length of alphabet used\n",
    "print(len(list(set(''.join(common_sentences)))))\n",
    "\n",
    "## Number of unique words\n",
    "print(len(list(' '.join(common_sentences).split(' '))))\n",
    "print(len(list(set(' '.join(common_sentences).split(' ')))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, dropout_prob=0.1):\n",
    "        super(GRUTextGenerator, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding_ff = nn.Linear(vocab_size, embed_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Dropout layer\n",
    "        \n",
    "        self.gru1 = nn.GRU(embed_size, hidden_size, 1, batch_first=True)\n",
    "        self.gru2 = nn.GRU(hidden_size, hidden_size, 1, batch_first=True)\n",
    "        self.gru3 = nn.GRU(hidden_size, hidden_size, 1, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = torch.nn.functional.one_hot(x, num_classes=self.vocab_size).float()\n",
    "        embedded = self.embedding_ff(x)\n",
    "        embedded = self.dropout(embedded)  # Apply dropout to the embedded input\n",
    "        \n",
    "        x, hidden1 = self.gru1(embedded, hidden)  # Optionally pass hidden state\n",
    "        x = self.dropout(x)  # Apply dropout after first GRU\n",
    "        \n",
    "        x, hidden2 = self.gru2(x, hidden1) \n",
    "        x = self.dropout(x)  # Apply dropout after second GRU\n",
    "        \n",
    "        x, hidden3 = self.gru3(x, hidden2)\n",
    "        x = self.dropout(x)  # Apply dropout after third GRU\n",
    "        \n",
    "        logits = self.fc(x)  # (batch_size, seq_length, vocab_size)\n",
    "        return logits, hidden3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example hyperparameters\n",
    "vocab_size = 28  # a-z and space, \\n chars\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "batch_size = 64\n",
    "\n",
    "# Create the model\n",
    "model = GRUTextGenerator(vocab_size, embed_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from model_cache/model_epoch_41.pt\n"
     ]
    }
   ],
   "source": [
    "def load_model(model, model_path, device):\n",
    "    # Load the saved model state dictionary\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "load_model(model, 'model_cache/model_epoch_41.pt', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloaders, vocab_size, device, epochs=10, startepoch=0, lr=0.0001, save_dir='model_cache'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    for epoch in range(startepoch, epochs):\n",
    "        total_loss = 0\n",
    "        for data_loader in dataloaders:\n",
    "            for _, (inputs, targets) in enumerate(data_loader, 0):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                logits, _ = model(inputs)  # (batch_size, seq_length, vocab_size)\n",
    "                logits = logits[:, -1, :]\n",
    "                logits = logits.view(-1, vocab_size)  # Reshape for loss calculation\n",
    "                targets = targets.view(-1)  # Reshape to match logits\n",
    "                \n",
    "                loss = criterion(logits, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss}\")\n",
    "\n",
    "        # Save the model after each epoch\n",
    "        model_path = os.path.join(save_dir, f'model_epoch_{epoch+1}.pt')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/60, Loss: 634.1374777057208\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m TextDataset(common_sentences, i)\n\u001b[1;32m      4\u001b[0m     dataloaders\u001b[38;5;241m.\u001b[39mappend(DataLoader(dataset, batch_size))\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloaders, vocab_size, device, epochs, startepoch, lr, save_dir)\u001b[0m\n\u001b[1;32m     24\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(logits, targets)\n\u001b[1;32m     25\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 26\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:385\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    384\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 385\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    388\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataloaders = []\n",
    "for i in range(1, max([len(x) for x in common_sentences])):\n",
    "    dataset = TextDataset(common_sentences, i)\n",
    "    dataloaders.append(DataLoader(dataset, batch_size))\n",
    "\n",
    "train(model, dataloaders, vocab_size, device, epochs=60, startepoch=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 608.1454376026813\n",
      "Epoch 2/30, Loss: 563.2294858114619\n",
      "Epoch 3/30, Loss: 544.8194607591286\n",
      "Epoch 4/30, Loss: 529.7589799932903\n",
      "Epoch 5/30, Loss: 515.4921694583754\n",
      "Epoch 6/30, Loss: 502.8573411722464\n",
      "Epoch 7/30, Loss: 490.9804561040073\n",
      "Epoch 8/30, Loss: 480.8322412063717\n",
      "Epoch 9/30, Loss: 471.6131476057344\n",
      "Epoch 10/30, Loss: 463.9399711136939\n",
      "Epoch 11/30, Loss: 457.81447389251844\n",
      "Epoch 12/30, Loss: 453.3699862015201\n",
      "Epoch 13/30, Loss: 449.7135527845239\n",
      "Epoch 14/30, Loss: 446.9867386568949\n",
      "Epoch 15/30, Loss: 445.03602773435705\n",
      "Epoch 16/30, Loss: 443.9416082640746\n",
      "Epoch 17/30, Loss: 442.7421854867789\n",
      "Epoch 18/30, Loss: 442.38801891756884\n",
      "Epoch 19/30, Loss: 442.86027276951063\n",
      "Epoch 20/30, Loss: 442.71631350391544\n",
      "Epoch 21/30, Loss: 441.7902618972148\n",
      "Epoch 22/30, Loss: 440.5920065352693\n",
      "Epoch 23/30, Loss: 437.9726842156233\n",
      "Epoch 24/30, Loss: 434.216297050094\n",
      "Epoch 25/30, Loss: 431.9342754115496\n",
      "Epoch 26/30, Loss: 430.6583996892441\n",
      "Epoch 27/30, Loss: 429.9540345290152\n",
      "Epoch 28/30, Loss: 432.19992955451016\n",
      "Epoch 29/30, Loss: 433.6042653270415\n",
      "Epoch 30/30, Loss: 432.7595517560403\n"
     ]
    }
   ],
   "source": [
    "dataloaders = []\n",
    "for i in range(1, max([len(x) for x in common_sentences])):\n",
    "    dataset = TextDataset(common_sentences, i)\n",
    "    dataloaders.append(DataLoader(dataset, batch_size))\n",
    "\n",
    "train(model, dataloaders, vocab_size, device, epochs=60, startepoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise(sentence):\n",
    "    return torch.tensor([token_dict[x] for x in sentence], dtype=torch.int64, device=device)\n",
    "\n",
    "def softmax(logits, temperature=1.0):\n",
    "    scaled_logits = logits / temperature\n",
    "    exp_logits = np.exp(scaled_logits - np.max(scaled_logits))\n",
    "    probs = exp_logits / exp_logits.sum()\n",
    "    return probs\n",
    "\n",
    "def run_inference(model, sentence, temperature=1.0):\n",
    "    model.eval()\n",
    "\n",
    "    input = vectorise(sentence)\n",
    "\n",
    "    output = model(input)\n",
    "\n",
    "    logits = output[0][-1, :].detach().numpy()\n",
    "\n",
    "    # print(logits)\n",
    "\n",
    "    # # Compute probabilities using softmax with temperature\n",
    "    # probs = softmax(logits, temperature)\n",
    "\n",
    "    # # Randomly sample from the probability distribution\n",
    "    # sampled_idx = np.random.choice(len(probs), p=probs)\n",
    "\n",
    "    sampled_idx = np.argmax(logits)\n",
    "    # print(sampled_idx)\n",
    "\n",
    "    # Find the corresponding token\n",
    "    for a, i in token_dict.items():\n",
    "        if sampled_idx == i:\n",
    "            sentence += a\n",
    "            return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can i see this you always\n"
     ]
    }
   ],
   "source": [
    "sentence = random.sample(string.ascii_lowercase, 1)[0]\n",
    "sentence = 'c'\n",
    "print(sentence, end='')\n",
    "\n",
    "while sentence[-1] != '\\n':\n",
    "    sentence = run_inference(model, sentence, temperature=0.6)\n",
    "    print(sentence[-1], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from json import JSONEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeTensor(JSONEncoder,Dataset):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.cpu().detach().numpy().tolist()\n",
    "        return super(json.NpEncoder, self).default(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = vectorise(sentence)\n",
    "# y = model(x)[0]\n",
    "\n",
    "# np.savetxt('test_data/generative_gru_x.csv', x.detach(), delimiter=',')\n",
    "# np.savetxt('test_data/generative_gru_y.csv', y.detach(), delimiter=',')\n",
    "\n",
    "with open('models/generative_gru.json', 'w') as json_file:\n",
    "    json.dump(model.state_dict(), json_file,cls=EncodeTensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
